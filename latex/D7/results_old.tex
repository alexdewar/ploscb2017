\section{Results}
R2 neurons have long been established to be involved in the processing of visual patterns \cite{Pan2009,Liu2006,Ernst1999}.
The R4d cells, although not critical for discrimination tasks, have been implicated in a task involving a learned heading relative to a pattern \cite{Guo2015} and, along with other ring neurons, novelty detection for visual patterns \cite{Solanki2015}.
Strikingly, \emph{Drosophila} are able to perform these tasks with only a tiny number of such neurons (R2: 28 \cite{Seelig2013}; R4d: 14 \cite{Seelig2013}; total ring neurons: approx. 63\cite{MartinPena2014}).
Early work into visual pattern discrimination in \emph{Drosophila} suggested that flies were comparing patterns on the basis of retinotopic overlap \cite{Dill1995,Dill1993}.
This model, although offering predictive power for a limited pattern subset, was shown to be incapable of discriminating other patterns that were however discriminable by flies \cite{Ernst1999} and it is now generally assumed instead that flies are encoding the patterns on the basis of certain higher-order features, viz. size, orientation, elevation and vertical compactness \cite{Ernst1999,Liu2006,Pan2009}.
Here we refer to these two hypotheses as the `Retinotopic Model' and the `Cognitive Model', respectively.
In this paper we present another model, which makes use of more recent biological findings \cite{Seelig2013} showing the visual RFs of the R2 and R4d ring neurons: we term this the `RF model'.
Of these, it is the R2 neurons which are critical for pattern discrimination, specifically synaptic plasticity afforded by \emph{rutabaga} \cite{Pan2009,Wang2008,Liu2006,Ernst1999}\todo{to self: fix cits}.
Our model compares the outputs that the RFs of these cells would predict, on the assumption that discrimination between two patterns will be easier for patterns with a greater `neuron-wise' difference in output.
%More recently, work by Seelig and Jayaraman \cite{Seelig2013} showing the RFs of the critically important R2 neurons presents an intriguing third possibility, namely that discrimination is performed on the basis of simple differences in outputs of the R2 cells; we have termed this the `RF Model'.
%We feel this approach has the advantage of remaining parsimonious whilst yielding strong predictive power.
With this information-based approach we were able to replicate behavioural results, without introducing any `black boxes'.

\texthl{[I haven't included anything about `bar detection' or `bar homing' here -- I cut it out before as discussed.
Have some notes though: see below.]}

There are two separate aspects to the ring neuron outputs that we wished to examine.
First, we wanted to compare the Retinotopic and RF Models of pattern discrimination, which, unlike the Cognitive Model, make no assumptions about higher-order processing of stimuli.
Here we found that the output of the RF Model, but not of the Retinotopic Model was significantly correlated with flies' ability to learn pattern distinctions.
This indicates that a simple mechanism could underlie pattern discrimination, with no higher-order processing required.

Second, we wanted to know what kind of visual information passes through the narrow bottleneck given by this small number of cells.
For this, we trained a series of \acp{ANN} to recover various higher-order properties from randomly generated stimuli, with input from either raw pixel information ($N=28$), or from the R2, R4d or R2 and R4d filters.
This showed that, despite the lack of specific encoding for any one of these parameters, nonetheless they are to an extent implicitly encoded in the outputs and hence could be extracted by a neural mechanism upstream.

\subsection{Bar homing}
\texthl{
Things to maybe include: \\
-- discussion of pid that will be in Fig. 1 (but isn't yet) \\
-- are RFs orientation detectors or more binary `is it vertical or not' detectors? \\
-- is this vertical tuning related to ecology? \\
-- is it something like the oblique effect?

Papers: \\
-- Neuser et al.'s paper on STM for bar position in R4s \\
-- other paper about learning a heading relative to a pattern in R4s \\
-- the new S\&J paper 
}

\subsection{Pattern Recognition}
We first compared two models of visual pattern discrimination in \emph{Drosophila} -- the Retinotopic Model \cite{Dill1995,Dill1993} and our own RF Model -- using a simulation of a standard behavioural paradigm.

The standard paradigm for testing pattern discrimination in \emph{Drosophila} \cite{Pan2009,Liu2006,Ernst1999,Dill1993}, involves tethering a fly in a drum with alternating patterns on the inside (Fig.~\ref{fig:recap}A).
When the fly attempts to rotate about the yaw-axis, the pattern on the drum is rotated by a corresponding amount in the opposite direction, giving closed-loop control.
Conditioning is aversive: Fixation upon certain portions of one of the patterns is punished with heat from a laser.
Hence, if the fly can discriminate the patterns, it will orient towards the non-punished pattern.

To recreate the visual information perceived by flies in such experiments, we simulated a typical experimental flight arena with a fly tethered in the centre.
We examined the difference in the output of R2 filters between patterns for each pattern pair (Fig.~\ref{fig:recap}B and C, see \emph{Materials and Methods} for details); the greater the difference, the more discriminable the patterns are for these neurons.
The pairs of patterns we used were drawn from \cite{Ernst1999}.
We have numbered pattern pairs according to the figure in which they appear in \cite{Ernst1999}, e.g. Set~\emph{(2)} refers to the patterns shown in Fig.~2 of that work (see Fig.~\ref{fig:pattern}).
We found a significant correlation between the strength of the learning index in Ernst and Heisenberg \cite{Ernst1999} and the difference we found in R2 activation (Spearman's rank, $n=34, \rho=.615, p<.005$).
By contrast, the proportion of retinal overlap was not significantly correlated with the flies' learning index for different pattern pairs (Spearman's rank, $n=34, \rho= -0.215, p=\mathrm{n.s.}$), suggesting that the outputs of R2 filters more closely approximate \emph{Drosophila} behaviour.
Interestingly, this implies that flies could reliably discriminate pairs of patterns without explicitly coding for the kinds of visual parameters commonly believed to underlie this discrimination \cite{Pan2009,Liu2006,Ernst1999}.
We also compared the performance of these two models with the flies' spontaneous preference (Fig.~\ref{fig:pattern}D and E).
The correlations for the Retinotopic and RF Models were both non-significant, although for the former there was a trend ($p<.1$).
This is in keeping with research showing that R2 neurons alone are critical for \emph{learned} pattern differences, but not spontaneous preferences, which, by contrast, seem to result from the activity across all subsets of ring neurons \texthl{[cit]}.
We next discuss specific pattern sets in detail.

If we turn to Fig.~\ref{fig:pattern}, Set~\emph{(2)}, we can see that these pattern pairs -- unlearnable by flies -- also give only small differences in outputs for the R2 filters.
This may seem surprising, given that these patterns appear so different from one another to our human eyes (and they are also very dissimilar if compared retinotopically).
However, the \emph{Drosophila} visual system as compared to the human visual system is far more informationally sparse, particularly in the subsystem we are here examining.
While the V1 region of human visual cortex contains neurons with small RFs representing a range of orientations across the visual field, these ring neurons have large RFs and poor orientation-resolution.
Hence, diagonal lines facing left and right, for example, are not discriminable by flies, and nor in fact would perceiving this difference be useful for carrying out a natural behaviour.

Other pattern sets, which may appear fairly similar to us, are nonetheless readily discriminable by flies and the simulation.
For example, Set~\emph{(9)} contains pairs of `triangles' (either a filled equilateral triangle, or a long and short bar arranged on top of one another), one facing up and the other down.
They are aligned either along the top and bottom or about the vertical centre of mass.
Flies are able to discriminate the former, but not the latter types of stimuli \cite{Ernst1999}.
Likewise, the R2 outputs show a smaller relative difference for the triangles aligned about the centre of mass than not, yet do so without explicitly coding for this parameter.
However, if the placement and form of the RFs is considered, the reason for the failure becomes more obvious (see Fig.~\ref{fig:simdiffpatts}).
The excitatory regions of the RFs can be seen to fall roughly across the middles of the triangles that are not aligned about vertical centre of mass; activation will therefore be greater for triangles up one way \emph{vs} another.
If the triangles are then offset, so as to be aligned about the vertical centre of mass, then the triangles will be about as thick at the points where the R2 RFs will cover them and the difference in activation will be lower.

Another interesting pattern pair, Set~\emph{(6)}, consisting of only one pair, a large and a small square, was readily discriminable by both flies and the R2 filters.
While it could be that flies are explicitly coding the size of the squares, the R2 filters do not and yet are able to distinguish them readily.
However, this does not mean that the information is not there implicitly (see below).
\todo{could possibly include bit about designing shapes that look different but give similar activations etc.}

There are, however, some discrepancies.
The flies in \cite{Ernst1999} in a couple of cases were better at discriminating pairs of horizontal than vertical lines (Set~\emph{(3)} \emph{vs} Set~\emph{(4)}, and the pairs in Set~\emph{(12)}, marked with red Xs in Fig.~\ref{fig:pattern}), whereas the R2 filters performed approximately as well on both.
This may be because while our R2 filters are being presented with static stimulus pairs, for the flies the patterns were moving around horizontally, as noted in \cite{Ernst1999}.
\todo{could do simple simulation of this}

We have shown that flies' performance on a pattern discrimination task can be matched with a simple model of R2 population activity.
However, it is not necessarily the case that these cells evolved for the purpose of discriminating arbitrary visual stimuli, as in the experimental task.
In fact, a simple test involving adding RFs showed that improved performance on this task could have been achieved easily by evolution (data not shown).
This suggests that R2 neurons evolved either for a different, specific task, or as more general purpose mechanism for operant conditioning (see Discussion).

\subsection{What information is preserved in these neurons?}
\todo{I haven't changed this bit yet to reflect the new figures: i.e. first-order and second-order info}
We were also interested in discovering what properties of visual stimuli, while not explicitly coded for by the ring neurons, may nonetheless be implicitly conveyed in the population outputs.
To do this, we trained a series of neural networks to discriminate sets of randomly generated stimuli -- ellipse-like `blobs' -- on the basis of specific parameters (see \emph{Materials and Methods} for details).
The networks were given as inputs either raw images of the stimuli, or the outputs of the R2, R4d or R2 and R4d filters presented with the same stimuli.

We first looked at whether the neural networks could be trained to extract positional information about a stimulus: elevation and azimuth.
The stimuli used were ellipse-like `blobs', with orientation and major-axis length held constant ($\mathrm{orientation} = 0\degree, a = 30\degree$).
There were 100 possible azimuths and 100 possible elevations, giving a total of 10,000 stimuli.
Of these, 4000 were used for training and 6000 for testing.
Results are shown in Fig.~\ref{fig:elaz}.
The neural networks were indeed able to extract information about elevation and azimuth based on any of the input types.
Performance was better with parameter values nearer the middle, as at the extremes the stimuli lay partially outside the visual field.
Though overall performance was best with raw views, it was also good with the sets of ring neuron inputs, indicating that these ring neurons implicitly convey information about these parameters.

We next trained the same kind of networks to extract information about properties on the basis of which \emph{Drosophila} are known to be able to discriminate visual stimuli \cite{Pan2009,Liu2006,Ernst1999}: orientation, size and elevation.
The stimuli were again randomly generated ellipse-like blobs.
Ten different orientations, sizes and elevations were used, giving a total of 1000 stimuli, of which 400 were used for training and 600 for testing.
The networks were again able to extract information about orientation, size and elevation (Fig.~\ref{fig:orsiel}).
The `elevation' parameter, as with the previous experiment, shows poorer performance at the extremes.
`Orientation' was the parameter with the highest error scores, presumably because it represents a second-order property, unlike elevation and size.
Nonetheless, all three parameters could be simultaneously estimated by a neural network with ring neuron inputs, indicating that flies could be trained to distinguish arbitrary stimuli differing along these parameters.

%\subsection{Summary}
In summary, we have shown that information about a number of higher-order properties, taken from the Cognitive Model, passes through the bottleneck of this small number of neurons.
This indicates that such information could be used in some way upstream of the ring neurons, perhaps as an explicit encoding, although the information could also be used implicitly.
However, as we have shown in the previous section, in order to perform a pattern discrimination task, such an explicit coding is not necessary.
Likewise, presumably there are other tasks in which R2 neurons play a role where extraction of these parameters is either not necessary or would even hinder performance.
