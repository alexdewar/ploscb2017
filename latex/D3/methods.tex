
\section*{Methods}
\subsection*{Pre-processing the receptive fields}
\label{sec:methods:preprocessing}
The \ac{RF} data were drawn from \cite{Seelig2013} (Extended Data Figure 8), which comprised measurements from 7 R2 glomeruli and 14 R4d glomeruli in the lateral triangle; the precise number of flies included varied by glomerulus ($2\le N\le 7$).
We first processed the data into a form suitable for use in our simulations.
Here, as throughout, Matlab\textregistered\ (MathWorks, Natick, MA, USA) was used to perform all calculations.

The data were in the form of images, one for each fly for a given glomerulus, with red areas for excitatory regions and blue for inhibitory.
Each point on the image was assigned a value ranging from --1 to 1, based on the values given by the colour bars in \cite{Seelig2013}, maximum inhibition and excitation, respectively.
These values were then thresholded:
$$
g_{i,j} = \left\{ \begin{array}{rl}
		   1 & \mbox{for } I_{i,j} \ge T; \\
                   -1 & \mbox{for } I_{i,j} \le -T; \\
                   0 & \mbox{otherwise.}
                  \end{array}
          \right.
$$
where $g_{i,j}$ is the ($i,j$)th pixel of the thresholded kernel, $I_{i,j}$ is the ($i,j$)th value of the processed receptive field image and $T$ is the threshold value, here $0.25$.

The centroid for the largest excitatory region, at coordinates $(x,y)$, is calculated using Matlab's \texttt{regionprops} function on an image with values of 1 for positive values and 0 otherwise.
The mean centroid, $(\bar{x},\bar{y})$, across flies is also calculated, and the kernels are recentred to these coordinates:
$$
\hat{g}_{i,j} = \left\{ \begin{array}{ll} g_{i+y-\bar{y},j+x-\bar{x}} & \mbox{for } 1\le i+y-\bar{y}\le m \mbox{ and } 1\le j+x-\bar{x}\le n;\\
0 & \mbox{otherwise.} \end{array} \right.
$$

We next calculate the average \ac{RF} across flies, $\bar{g}_{i,j}$, and threshold again:
\begin{align*}
\bar{g}_{i,j} &= \left\{ \begin{array}{rl}
			0 & \mbox{for } c \le -T; \\
			1 & \mbox{for } c \ge T; \\
			\frac{1}{2} & \mbox{otherwise.} 
			\end{array} \right. \\
\mbox{where } c &= \frac{1}{|\mathbf{G}|}\sum\limits_{\hat{g} \in \mathbf{G}} \hat{g}_{i,j}
\end{align*}
where $\mathbf{G}$ is the set of kernels being averaged and $T$ is the threshold (again: 0.25).
In this case, however, the \ac{RF} is given a value of 1 for excitation, 0 for inhibition and $\frac{1}{2}$ for no activity.

In order to calculate the activation for a given \ac{RF} on presentation of an image, $I$, the \ac{RF} must first be resized to the same size as the image.
This is accomplished by resizing the average \ac{RF}, $\bar{g}_{i,j}$, with Matlab's \texttt{imresize} function to the same dimensions as $I$.
Finally, the kernel is rethresholded and the excitatory and inhibitory regions are assigned different values:
$$
K_{i,j} = \left\{
\begin{array}{rl}
\left( \sum\limits^m_{i=1}\sum\limits^n_{j=1}[\bar{g}_{i,j} \ge \frac{1+T}{2}] \right)^{-1}, & \mbox{for } \bar{g}_{i,j} = 1; \\
-\left( \sum\limits^m_{i=1}\sum\limits^n_{j=1}[\bar{g}_{i,j} \le \frac{1-T}{2}] \right)^{-1}, & \mbox{for } \bar{g}_{i,j} = 0; \\
0, & \mbox{otherwise.}
\end{array}
\right.
$$
This method of allocating values has the result that $\sum\limits_{i=1}^m \sum\limits_{j=1}^n K_{i,j}=0$.

The activation of an average kernel, $K$, to the presentation of an image stimulus, $I$, is then:
$$
\begin{array}{rl}
A(I,K) = {\sum\limits^m_{i=1} \sum\limits^n_{j=1} I_{i,j}K_{i,j}}, &\mathrm{where\ } 0 \le I_{i,j} \le 1
\end{array}
$$
where $I_{i,j}$ and $K_{i,j}$ are the ($i,j$)th pixels of the image and kernel, respectively.

\subsection*{Can we replicate behavioural experiments?}
\label{sec:methods:recap}
We first examined whether the output of these populations of \acp{RF} could qualitatively replicate results from the behavioural literature.
The two tasks we focused on were bar and edge fixation \cite{Neuser2008,Osorio1990} and pattern discrimination \cite{Liu2006,Ernst1999}.

Figure~\ref{fig:recap}A~\&~B shows the population response of R4d neurons to bars of two different widths.
The population response was calculated by taking the mean of the individual activations of the \acp{RF}.
Note that the difference between the activations of the left-hand and right-hand neurons would be sufficient to drive fixation to a vertical bar, a behaviour flies are known to engage in spontaneously [cit].

There is a paradigm for testing pattern recognition in \emph{Drosophila} \cite{Pan2009,Liu2006,Ernst1999}, in which a tethered fly is placed into a drum with repeating visual patterns projected onto the inside (see Figure~\ref{fig:pattern} for examples).
When the fly attempts to rotate about the yaw-axis, the pattern on the drum is shifted by a corresponding amount in the opposite direction, giving the illusion of closed-loop control.
Conditioning is aversive: fixation upon certain portions of the pattern is punished with heat from a laser.
To recreate this paradigm, we used a modified version of the \ac{RIDF} \cite{Philippides2011,Zeil2003}.
In the standard version of the \ac{RIDF}, an image is recorded at a goal location and homing back to that location is achieved by repeatedly rotating on the spot and heading in the direction for which the \ac{rms} difference between current and goal views is at a minimum.
In our case, instead of raw pixel content of views, we used the activations of individual R2 neurons.
The `goal view' was taken to be the activation of the cells when the fly is facing the unpunished pattern.
The \ac{rms} difference between activation for rotated and unrotated views was then calculated (Figure~\ref{fig:recap}C--F):
$$
r(I,\theta,\mathbf{G}) = \frac{1}{|\mathbf{G}|\cdot mn} {\sum\limits_{K \in \mathbf{G}} \sum\limits^n_{j=1} \sum\limits^m_{i=1} (I_{i,j}(0)-I_{i,j}(-\theta))^2 \cdot {K_{i,j}}^2}
$$
where $r(I,\theta,\mathbf{G})$ indicates the \ac{rms} difference between the activations of the set of \acp{RF}, $\mathbf{G}$, for an image, $I$, and the same image at rotation $-\theta$ (i.e. opposite to the fly's direction of motion), such that if the population code shows a different value when the fly is facing the rewarded and unrewarded pattern the \acp{RF} are encoding the difference between the two patterns.

\subsection*{What information is preserved in these neurons?}
Neural networks were used as a statistical device to test what properties of a visual stimulus are still encompassed by the population code of a simple network, after `passing through' the ring-neuron \acp{RF}.
Two-layer feedforward networks with 10 hidden units, optimised with the scaled conjugate gradient function, were used throughout; these were implemented using the \texttt{Netlab} toolbox for Matlab \cite{netlab}.

\subsubsection*{Stimuli}
\label{sec:methods:stimuli}
The stimuli with which the networks were trained were a series of black `blobs' on a white background.
The blobs were based on ellipses with a fixed ratio between the lengths of the major and minor axes ($2:1$), with the radii modified with complex waves:
$$
r \le \left(\frac{\cos^2 \theta}{2} + \frac{\sin^2 \theta}{a} \right)^{-1} + W(\theta)
$$
where $a$ is the length of the major axis and $W(\theta)$ is a complex wave defined as:
$$
W(\theta) = \sum_{i=1}^n W_i(\theta) = \sum_{i=1}^n A_i \sin f_i (\theta+\phi_i) 
$$
where $A_i$, $f_i$ and $\phi_i$ describe the maximum amplitude, frequency and phase shift of the wave $W_i(\theta)$, respectively.
In these experiments, $A_i$, $f_i$ and $\phi_i$ were randomly generated and $n=5$.

\subsubsection*{Grading performance of neural networks}
The performance of neural networks was graded by calculating the \ac{rms} difference between the matrix of true values for the parameters with the network's output:
$$
E(\mathbf{y},\mathbf{t}) = \sqrt{\frac{\sum\limits_{i=1}^{n} (\mathbf{y}_i-\mathbf{t}_i)^2}{n}}
$$
where $E(\mathbf{y},\mathbf{t})$ is the mean error score, computed from the vector of outputs given by the network, $\mathbf{y}$, and the vector of true values, $\mathbf{t}$.
Hence, for a network that computed the values of all parameters accurately, a graph of the network's output \emph{vs.} the true values would give the line $y=x$ and an error score of 0 over the whole range of values.

