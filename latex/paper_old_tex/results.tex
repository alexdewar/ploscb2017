\section*{Results}
[PRG 10/9/15] 

The neurogenetic tools that are available in Drosophila neuroethology have enabled researchers to identify specific sub-populations of visual cells that are required for particular visually-guided behaviours. More recently this has been augmented by detailed descriptions of the response properties of the visual cells involved \cite{Seelig2013}. Putting these two things together, we have an opportunity to investigate the outputs of populations of visual cells in simulations of well-known behavioural experiments (Figure 1A, E). By doing this we can understand the task-specific information provided by sub-populations of visual cells. A corollary of this approach is that we can also gain a tighter understanding of the visual information available for the control of specific behaviours. This promotes a bottom-up sensorimotor account of complex behaviour (Chittka, L., Rossiter, S. J., Skorupski, P., \& Fernando, C. (2012). What is comparable in comparative cognition?. Philosophical Transactions of the Royal Society B: Biological Sciences, 367(1603), 2677-2685.; Wystrach, A., \& Graham, P. (2012). What can we learn from studies of insect navigation?. Animal Behaviour, 84(1), 13-20.) in insects, in contrast to  top-down cognitive accounts (Avargu√®s-Weber, A., Deisig, N., \& Giurfa, M. (2011). Visual cognition in social insects. Annual review of entomology, 56, 423-443.).

\subsection*{Simulating the outputs of visually responsive ring neurons}
\label{sec:results:bar}
\cite{Seelig2013} were able to look at the activity of ring neurons because their cell bodies are in specific glomeruli in the lateral triangle which is amenable to calcium imaging. In their paper they present results from multiple flies which we
have combined in order to obtain sets of `canonical' Receptive Fields (RFs). The activity profiles in specific glomeruli were consistent across flies \cite{Seelig2013}, combining RFs is therefore permissable and simply reduces the impact of any measurement error. This gave us a set of 28 R2 and 14 R4d filters(for details, see \emph{Methods}).

Like mammalian simple cells [cite hubel and cite wystrach dispatch], the R2 and R4d ring neurons have RFs characteristic of bar and edge detectors (compare, e.g., R4d glom. 1 and R2 glom. 7 in Fig.~\ref{fig:avkernels}D).
However ring neuron RFs are coarser, covering a much larger region of the visual field, and are mostly tuned to orientations near the vertical (with a small number horizontally tuned). Output values for a given visual stimulus can then be calculated by convolution with the sets of averaged ring neuron filters, after appropriate scaling. This gives a population code whereby the outputs of the set of filters is the encoded 'representation' of the current visual stimulus.

\subsection*{Orientation towards bar stimuli}
As described above, flies will spontaneously orient towards black bars (Gotz ref as above). More detailed assays show that flies will aim for the centre of narrow bars, and for the edges of wide bars [ref]. In our first analysis we looked at the response of populations of simulated ring neurons to bars of different widths (Figure 1A and B). Looking at the summed output of the ensembles of ring neurons we see that activation profiles show peak responses in the same places (Figure 1B). R2 neurons respond maximally to the inside edges of large bars, which is where flies head when presented with wide vertical bars [ref]. For R4d neurons, peaks in activation occur at a bar's centre and also at roughly +-90 to it. Although we don't know the details of mechanisms down-stream of these ring neurons what this modelling gives is existence proof that sufficient information is present in the sparse ring neuron code for the control of behaviour. Indeed, we can close the loop between sensory systems and behaviour by designing a simple PID controller (proportional-integral-derivative controller) (Figure 1C). A hypothetical agent whose steering commands are directly derived from the ring neuron ensemble code demonstrates bar fixation when far from a bar and fixation of the edges of a bar when the agent is nearer and therefore the apparent size is greater too (Figure 1D).

Through the example of bar fixation we have shown how the outputs of small populations of visually responsive ring neurons are ideally suited for control of behaviour. This simple example shows how we can relate the information present in an ensemble of sensory cells to a particular behaviour. We now turn to a more complex behaviour.

\subsection*{Pattern Discrimination in flies and Ring Neuron population codes}
\label{sec:results:pattern}

The standard paradigm for testing pattern discrimination in \emph{Drosophila} \cite{Pan2009,Liu2006,Ernst1999,Dill1993}, involves tethering a fly in a drum with a pair of alternating patterns on the inside wall of the drum (Fig.~\ref{fig:recap}A).
When the fly attempts to rotate about the yaw-axis, the pattern on the drum is rotated by a corresponding amount in the opposite direction, giving closed-loop control.
Conditioning is aversive: Fixation on one of the patterns is punished with heat from a laser.
Hence, if the fly can discriminate the patterns, it will orient towards the non-punished pattern. The ability to discriminate patterns in such an assay depends on R2 neurons, specifically synaptic plasticity afforded by \emph{rutabaga} \cite{Pan2009,Wang2008,Liu2006,Ernst1999}. Through analogy to artificial neural networks, we can relate flies' ability to learn to discriminate patterns to changing the output weights of the R2 population code. 

To recreate the visual information perceived by flies in such experiments, we simulated a typical experimental flight arena with a fly tethered in the centre. We then examined the output of the ensembles of ring neurons for a fly fixating the two patterns within a stimulus pair. Figure 1 shows one way we can analyse this by looking at the simple difference between the ensemble outputs for simulated flies looking at the patterns within a pattern pair. We do this by taking the Root Mean Square difference between the ensemble ouput for a simulated fly oriented at 0deg (i.e. view centered on one pattern) and the ensemble output when the 'fly' is oriented at 90deg (i.e. centered on the other pattern). For greater RMS differences there is essentially a larger signal on which plasticity can work to drive pattern discrimination. Therefore if simulation provides a good approximation of the visual information available to the pattern learning/discrimination systems of a fly, we should see a close relationship between the RMS difference in simulated R2 output for a pattern pair and the flies' ability to learn to discriminate that pattern pair.

We examined the difference in the outputs of the R2 filters between patterns from pairs (Fig.~\ref{fig:recap}B and C, see \emph{Materials and Methods} for details) drawn from \cite{Ernst1999}. Figure 2 shows these RMS differences, with pattern pairs numbered according to the figure in which they appear in \cite{Ernst1999}. In general, within these groups, the pattern pairs for which flies show a significant learned discrimination (in ref) have a greater RMS difference in R2 population activity. X out of XX pattern pairs where flies show significant learning have RMS difference in R2 activity about the overall average (Figure 2A, B). Whereas XY out of YY patterns that flies found more difficult to learn had RMS differences below average. Looking across all pattern pairs, we find a significant correlation between the strength of the learning index reported for flies in Ernst and Heisenberg \cite{Ernst1999} and the RMS difference we found in R2 activation (Spearman's rank, $n=34, r=.615, p<.005$).


For comparison we also perform a parallel analysis where we quantify the similarity of patterns within a pair based on the degree to which the patterns overlap. For this measure, there was no significant correlation with the flies' learning index over the pattern pairs (Spearman's rank, $n=34, r= -0.215, p=\mathrm{n.s.}$). This suggests that the very small population code from R2 cells is a more likely visual encoding for the pattern discrimination systems of the fly.

We additionally looked at the relationship between our two visual encodings (R2 population code and the simple retinotopic encoding)and the degree to which flies' show a spontaneous preference for one of the patterns within a pair before any conditioning procedureshave commenced (Fig.~\ref{fig:pattern}D and E). For both retinotopic encoding and R2 population codes there was no significant correlation. This is in keeping with research showing that R2 neurons alone are critical for \emph{learned} pattern differences, but not spontaneous preferences, which, by contrast, seem to result from activity across all subsets of ring neurons \texthl{[cit]}.
We next discuss specific pattern sets in detail.

Set~\emph{(2)} in Figure 2 gives examples of pattern pairs that are indiscriminable to flies and also give only small differences in outputs of R2 filters. This may seem surprising, given that these patterns appear quite different to human observers and are also very dissimilar if compared retinotopically. Thus we can see how the \emph{Drosophila} R2 ring neuron encoding is more informationally sparse. Whilst the human V1 region of human visual cortex contains neurons representing a full range of orientations all across the visual field, R2 neurons have large RFs and poor orientation-resolution.
Hence, a pattern pair consisiting of a diagonal lines facing left and a diagonal line facing right, for example, have only a small difference in R2 outputs in our simulation and are also not discriminable by flies. For example, Set~\emph{(9)} contains pairs of `triangles' (either a filled equilateral triangle, or a long and short bar arranged on top of one another), one facing up and the other down.
They are aligned either along the top and bottom or about their vertical centres of mass.
Flies are able to discriminate the former, but not the latter types of stimuli \cite{Ernst1999}. Likewise, if we inspect the RMS differences for pattern pairs of centre of mass aligned triangles or centre of mass unaliged triangles, we see a smaller relative difference for the aligned triangles. Looking at the placement and form of the R2 RFs allows us to determine where this difference comes from (see Fig.~\ref{fig:simdiffpatts}).
The excitatory regions of the RFs fall roughly across the middle of triangles that are not aligned about their vertical centre of mass the difference in width at this point will lead to differences in activation. If the triangles are offset (Figure 3b) so as to be aligned about their vertical centres of mass their width will be similar for the regions of peak R2 coverage and the difference in activation will be lower.

We can further emphasise this point, on the independence of apparant similarity of patterns and the visual encoding from R2 cells, by designing shape pairs (see Methods) that appear similar to humans, but are easily discriminable to the R2 encoding (Figure 3C). Simlarly, we can design hsape pairs that are considered similar to the R2 network, but not to human observers (or retinotopic overlap algorithms). Being able to design shapes on the basis of the expected output of the R2 population could be a very useful tool in the design of future behavioural experiments.

There are, however, some discrepancies where the learning performance of flies for a pattern pair does not match the RMS difference our R2 population code. In some cases flies are better at discriminating pairs of horizontal than vertical lines (Set~\emph{(3)} \emph{vs} Set~\emph{(4)}, and the pairs in Set~\emph{(12)}, marked with red Xs in Fig.~\ref{fig:pattern}). The RMS difference in the R2 population code discriminates horizontal and vertical patterns equally. This may be because while our R2 filters are being presented with static stimulus pairs, for the flies the patterns were moving around horizontally (as noted in \cite{Ernst1999}) making it much harder for flies to resolve horizontal information.

We have shown that the behavioural performance of flies on a pattern discrimination task if approximated by a simple difference metric applied to the R2 population activity of a small number of simulated R2 cells. However both flies and our R2 population are bad at a variety of seemingly simple pattern discriminations. A simple thought experiment is helpful in considering the purpose of the visual code provided by the small population of R2 neurons. IF we double the number of R2 neurons in our population ??by randomly placing their RF excitation centres as far apart as possible?? then the RMS difference for centre of mass aligned triangles would increase to levels similar to those for pattern pairs easily discriminated by flies. We can therefore see how the pattern discrimination ability of an R2-like neuronal population could easily have been imporved over evolutionary time without need for any radical architectural changes, simply through the addition of more R2 cells. We propose that there might be little selection pressure for sophisticated pattern recognition in flies, given how easily it could have evolved.

\subsection*{What information is preserved in this simple neural code?}

Having such a small number of cells providing a visual encoding is essentially a sensory bottleneck with information from x ommatidia condensed onto 28 R2 or 14 R4d ring neurons. We have shown above how this code provides sufficient information to dicriminate some patterns pairs. However general purpose pattern recognition seems unlikely to be a key visually guided behaviour for flies, as discrimination performance could be easily improved with the addition of more ring neurons in the R2 population. However looking at the pattern pairs which flies and the R2 population were able to discriminate we see that certain pattern parameters are implicitly coded for in the R2 population. Sets (6) and (9) suggest that shape size and vertical centre of mass are parameters that can be recovered from the R2 population code after the sensory bottleneck.

Here we address in more general terms the shape information that may be implicitly conveyed in the ring neuron population code.
To do this, we generate large sets of blob-like patterns (see Methods) that vary across a range of parameters (size, position, orientation). We then asked if an Artificial Neural Network (ANN) could be trained to recover this shape information from either a raw image of the shape (a control condition) or from the output of the R2/R4d population. In this way the ANNs are statistical engines interogating the ring neuron population code to determine the shape information that is implicit to the code and has therefore made it through the sensory bottleneck. 

We first looked at whether ANNs could be trained to extract simple positional information (elevation and azimuth) about a stimulus from the ring neuron population codes. 
The stimuli used were ellipse-like `blobs', with orientation and major-axis length held constant ($\mathrm{orientation} = 0\degree, a = 30\degree$).
There were 100 possible azimuths and 100 possible elevations, giving a total of 10,000 stimuli.
Of these, 4000 were used for training and 6000 for testing.
Results are shown in Fig.~\ref{fig:elaz}.
We see that ANNs are indeed able to extract information about elevation and azimuth based on any of the input types.
Performance was better with parameter values near the middle, as at the extremes, portions the stimuli lay outside the visual field of the simulated fly.
Overall performance was best when ANNs were trained with raw views (Figure 4C, D). However ANNs also performed well with ring neuron inputs. Thus we can see how very small populations of ring neurons retain simple positional information quite accurately.

We next trained the same kind of ANNs to decode information about more derived properties namely orientation and size.
The stimuli were again randomly generated ellipse-like blobs.
Ten different orientations and sizes were used, giving a total of 1000 stimuli, of which 400 were used for training and 600 for testing.
Figure 5 shows how the ANNs were again able to extract this shape information from raw images and the sparse rinf neuron codes. Orientation' was the parameter with the highest error scores, presumably because it represents a second-order property, unlike elevation and size.
Nonetheless, all three parameters could be simultaneously estimated by a neural network with ring neuron inputs, indicating that flies could be trained to distinguish arbitrary stimuli differing along these parameters.

In summary, we have shown that information about a number of higher-order shape properties passes through the bottleneck created by the small number of ring neurons.
This indicates that such information is available upstream of the ring neurons for the guidance of behaviour. 
