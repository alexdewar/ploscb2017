\section*{Introduction}
Vision is known to play a role in a great number of behaviours performed by the fruitfly \emph{Drosophila melanogaster}, including mate-recognition, place homing, flight stabilisation, collision-avoidance, landing and escaping a looming object (like a hand, for example) [cits];
moreover, flies are able to produce these behaviours with only around 100,000 neurons [cit].
The diversity of visual behaviours produced by necessarily parsimonious computational mechanisms and the great range of neurogenetic techniques available for the study of \emph{Drosophila} make it a good model organism for this kind of study.

For some visual behaviours, we know a reasonable amount about the computational algorithm and its neural implementation.
For example, take collision-avoidance and landing in \emph{Drosophila}.
The behaviours are well characterised:
Collision-avoidance involves increased wing-beating on the side closest to the object to be avoided and landing involves an increase in wing-beating on both sides and an extension of the legs.
Both rely on optic flow detection, with the collision-avoidance and landing behaviours triggered by expansion in the lateral and vertical direction, respectively [cit], and relevant neurons have been identified in the lobula plate [check, poss. expand].
Though the exact mechanism is not known, the activity of the neurons responsive to loom can be accurately modelled with a `linear--non-linear' approach [de Vries; Chichilnisky; Tammero \& Dickinson; van Breugel \& Dickinson].

This `three-pronged' approach---1) identify a behaviour to study; 2) posit a computational mechanism; and 3) investigate the underlying `wetware' with behavioural experiments---lends itself well to the study of relatively simple visual reflexes and has accordingly proven very fruitful [e.g. Borst2014, etc.].
(Steps 2 and 3 can inform one another in a kind of `research loop.')
If we want to investigate more complex visual behaviours, however, such as pattern discrimination or place homing, each of these steps is made more difficult.
First, even identifying a set of actions performed as a unitary `behaviour' is problematic: Could the actions be the result of multiple behavioural systems, possibly ones that are not obviously related?
While escape from looming stimuli clearly represents a specialised behavioural system, with an obvious adaptive value, it is not so obvious with `higher-order' capacities, such as the ability to discriminate arbitrary visual patterns, which could well involve one or more systems evolved for an entirely different purpose [cit maybe Chittka et al.?].
Then there is the problem of both designing appropriate experiments:
For even a minimally complex stimulus there will be an infinite number of ways in which it can be described (e.g. a square can be described in terms of where its edges are, the number and position of its vertices, visual centre of mass, how closely it resembles a female fly, etc.).
The problem of determining the underlying computational process from the sparse behavioural data is therefore highly underdetermined.

Here we advocate the use of a synthetic approach, investigating in simulation what behavioural tasks can be performed by known neural systems.
In doing so, we suggest novel interpretations of the behavioural data that also have the advantage of being `neurally grounded.'
The neural data used are taken from Seelig and Jayaraman's \cite{Seelig2013} study of two classes of ring neuron in the \emph{Drosophila} ellipsoid body, a group of neurons known to be involved in visual behaviours (R1: place homing \cite{Ofstad2011,Sitaraman2010,Sitaraman2008}; R2/R4m: pattern recognition \cite{Pan2009,Liu2006,Ernst1999}; R3/R4d: bar fixation memory \cite{Neuser2008}).
The two subtypes of ring neuron investigated were the R2 and R4d ring neurons, of which only 28 and 14, respectively, were responsive to visual stimuli.

In this paper, we investigate two behaviours and how they relate to R2 and R4d ring neuron activity in simulation: bar fixation/homing (a `simple' behaviour) and pattern discrimination (a more complex behaviour).
R4d ring neurons are already known to be involved in spatial orientation memory for vertical bars [Neuser] and we suggest a mechanism here by which this may occur.
There is evidence that optic flow fields in the lobula plate are involved in homing to vertical bars [cit], but we suggest here that R2 ring neurons could in principle also have a role in flies' responses to bars, as the peak responses of simulated R2 neurons were at the centres of narrow vertical bars and the inside edges of larger ones, which corresponds to where real flies head [Osorio].

There have been a number of papers investigating the process of pattern recognition and its neural underpinnings in \emph{Drosophila} [Ernst \& Heisenberg, Liu \& al., Pan \& al., more...].
The standard paradigm involves putting a fly into a closed-loop system:
The fly is tethered in a drum inside which are two visual stimuli which alternate every 90\degree.
As the fly attempts to rotate in one direction, the drum rotates in the other, giving the closed-loop control.
With this paradigm, we have learned that both the fan-shaped body and ring neurons are critical for visual pattern memory [Pan, Liu].
Whereas the fan-shaped body encodes two parameters of visual stimuli---`elevation' and `contour elevation'---in separate strata, R2 and R4m ring neurons store these parameters, as well as `size' and `vertical compactness,' in a parameter-independent manner [Pan].
(Additionally, a number of visual patterns are known to be invariant for horizontal [Tang 2004], but not vertical [Dill, Wolf \& Heisenberg 1993] displacement.)
Here we verify that our population of simulated ring neurons are able to discriminate the visual patterns also discriminable by flies.
We then proceed to show that certain parameters---`orientation,' `size' and `elevation'---are implicit in the ring neurons' outputs.
We argue, however, that although a neural network furnished with ring neuron-like cells as input can be trained to distinguish stimuli differing along these parameters, having a mechanism to explicitly extract such features is an unnecessary and computationally expensive means of performing this task.
Results are discussed in terms of sparse encoding, with reference to minimalist models of visual behaviour that have been applied to other insects.
